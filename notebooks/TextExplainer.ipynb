{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextExplainer\n",
    "\n",
    "While eli5 supports many classifiers and preprocessing methods, it can't support them all. But if a library is  not supported by eli5 directly, or the text processing pipeline is too complex for eli5, eli5 can still help - it provides an implementation of LIME (Riberio et al., 2016) algorithm which allows to explain predictions of arbitrary classifiers (including text classifiers). `eli5.lime` can also help when it is hard to get exact mapping between model coefficients and text features, e.g. if there is dimension reduction involved.\n",
    "\n",
    "## Example problem: LSA+SVM for 20 Newsgroups dataset\n",
    "\n",
    "Let's load \"20 Newsgroups\" dataset and create a text processing pipeline which is hard to debug using conventional methods: SVM with RBF kernel trained on [LSA](https://en.wikipedia.org/wiki/Latent_semantic_analysis) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', \n",
    "              'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=('headers', 'footers'),\n",
    ")\n",
    "twenty_test = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=('headers', 'footers'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89014647137150471"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "vec = TfidfVectorizer(min_df=3, stop_words='english',\n",
    "                      ngram_range=(1, 2))\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "lsa = make_pipeline(vec, svd)\n",
    "\n",
    "clf = SVC(C=150, gamma=2e-2, probability=True)\n",
    "pipe = make_pipeline(lsa, clf)\n",
    "pipe.fit(twenty_train.data, twenty_train.target)\n",
    "pipe.score(twenty_test.data, twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dimension of the input documents is reduced to 100, and then a kernel SVM is used to classify the documents. \n",
    "\n",
    "This is what the pipeline returns for a document - it is pretty sure the first message in test data belongs to sci.med:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000 alt.atheism\n",
      "0.000 comp.graphics\n",
      "0.997 sci.med\n",
      "0.003 soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "# document to explain prediction for\n",
    "def print_prediction(doc):\n",
    "    y_pred = pipe.predict_proba([doc])[0]\n",
    "    for target, prob in zip(twenty_train.target_names, y_pred):\n",
    "        print(\"{:.3f} {}\".format(prob, target))    \n",
    "\n",
    "doc = twenty_test.data[0]\n",
    "print_prediction(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextExplainer\n",
    "Such pipelines are not supported by eli5 directly, but one can use eli5.lime.TextExplainer to debug the prediction - to check what was important in the document to make this decision.\n",
    "\n",
    "Note how we pass document and predict_proba function to TextExplainer.fit method (TextExplainer works best with probabilistic classifiers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=alt.atheism\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.000</b>, score <b>-10.474</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.420\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -10.054\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 96.19%); opacity: 0.81\" title=\"0.079\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.93%); opacity: 0.80\" title=\"0.013\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.91%); opacity: 0.82\" title=\"-0.232\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.88%); opacity: 0.81\" title=\"-0.156\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.73%); opacity: 0.81\" title=\"0.093\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.64%); opacity: 0.80\" title=\"-0.018\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.17%); opacity: 0.82\" title=\"-0.222\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.73%); opacity: 0.86\" title=\"-0.630\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.82%); opacity: 0.85\" title=\"-0.625\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 98.98%); opacity: 0.80\" title=\"-0.012\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.37%); opacity: 0.85\" title=\"0.541\">isn</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(120, 100.00%, 95.41%); opacity: 0.81\" title=\"0.103\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.44%); opacity: 0.82\" title=\"-0.172\">any</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 86.48%); opacity: 0.84\" title=\"-0.483\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.65%); opacity: 0.80\" title=\"-0.003\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.49%); opacity: 0.80\" title=\"-0.044\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.22%); opacity: 0.81\" title=\"-0.144\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.54%); opacity: 0.81\" title=\"-0.132\">anything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.81%); opacity: 0.82\" title=\"-0.279\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.33%); opacity: 0.80\" title=\"-0.048\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.44%); opacity: 0.80\" title=\"-0.045\">except</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.80%); opacity: 0.82\" title=\"-0.279\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.94%); opacity: 0.82\" title=\"-0.191\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.69%); opacity: 0.89\" title=\"-0.989\">pain</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 97.27%); opacity: 0.80\" title=\"0.049\">either</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.93%); opacity: 0.80\" title=\"0.033\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.24%); opacity: 0.81\" title=\"-0.078\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.04%); opacity: 0.81\" title=\"0.084\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.62%); opacity: 0.81\" title=\"-0.067\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.20%); opacity: 0.81\" title=\"0.079\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.08%); opacity: 0.82\" title=\"-0.186\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.64%); opacity: 0.81\" title=\"-0.066\">be</span><span style=\"opacity: 0.80\"> broken </span><span style=\"background-color: hsl(0, 100.00%, 92.40%); opacity: 0.82\" title=\"-0.212\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.17%); opacity: 0.82\" title=\"-0.222\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.40%); opacity: 0.80\" title=\"-0.023\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.34%); opacity: 0.82\" title=\"0.176\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.62%); opacity: 0.81\" title=\"-0.067\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.20%); opacity: 0.81\" title=\"0.079\">have</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 93.08%); opacity: 0.82\" title=\"-0.186\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.64%); opacity: 0.81\" title=\"-0.066\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.22%); opacity: 0.81\" title=\"0.110\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.44%); opacity: 0.81\" title=\"0.072\">surgically</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 98.80%); opacity: 0.80\" title=\"0.015\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.32%); opacity: 0.81\" title=\"-0.140\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.14%); opacity: 0.82\" title=\"-0.223\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.85%); opacity: 0.81\" title=\"0.060\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 91.15%); opacity: 0.82\" title=\"0.264\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.06%); opacity: 0.82\" title=\"0.226\">x</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 93.00%); opacity: 0.82\" title=\"-0.189\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.43%); opacity: 0.80\" title=\"-0.022\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.22%); opacity: 0.82\" title=\"0.261\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.68%); opacity: 0.81\" title=\"0.065\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.22%); opacity: 0.83\" title=\"0.304\">mention</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.15%); opacity: 0.80\" title=\"0.052\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.19%); opacity: 0.80\" title=\"0.009\">she</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(0, 100.00%, 94.89%); opacity: 0.81\" title=\"-0.120\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.90%); opacity: 0.81\" title=\"-0.059\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.73%); opacity: 0.86\" title=\"-0.630\">kidney</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 83.82%); opacity: 0.85\" title=\"-0.625\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.44%); opacity: 0.81\" title=\"-0.136\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.86%); opacity: 0.82\" title=\"-0.194\">children</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 92.90%); opacity: 0.82\" title=\"-0.192\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.94%); opacity: 0.82\" title=\"-0.191\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.15%); opacity: 0.81\" title=\"-0.080\">childbirth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.10%); opacity: 0.83\" title=\"-0.356\">hurt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.21%); opacity: 0.81\" title=\"-0.144\">less</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=comp.graphics\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.000</b>, score <b>-9.186</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.187\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.49%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -8.999\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 95.12%); opacity: 0.81\" title=\"-0.113\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.74%); opacity: 0.81\" title=\"-0.093\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.17%); opacity: 0.85\" title=\"-0.552\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.38%); opacity: 0.80\" title=\"-0.046\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.43%); opacity: 0.81\" title=\"-0.072\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.84%); opacity: 0.82\" title=\"0.195\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.02%); opacity: 0.81\" title=\"0.116\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.73%); opacity: 0.89\" title=\"-0.986\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.82%); opacity: 0.88\" title=\"-0.857\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 95.39%); opacity: 0.81\" title=\"-0.104\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.20%); opacity: 0.83\" title=\"-0.305\">isn</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(120, 100.00%, 97.28%); opacity: 0.80\" title=\"0.049\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.59%); opacity: 0.81\" title=\"0.098\">any</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 82.03%); opacity: 0.86\" title=\"-0.726\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.49%); opacity: 0.81\" title=\"-0.070\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.53%); opacity: 0.80\" title=\"-0.020\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.45%); opacity: 0.81\" title=\"0.072\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.68%); opacity: 0.81\" title=\"0.095\">anything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.01%); opacity: 0.82\" title=\"0.188\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.61%); opacity: 0.80\" title=\"-0.019\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.81%); opacity: 0.81\" title=\"-0.091\">except</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.48%); opacity: 0.81\" title=\"-0.101\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.27%); opacity: 0.83\" title=\"-0.348\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 64.95%); opacity: 0.97\" title=\"-1.885\">pain</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 94.24%); opacity: 0.81\" title=\"-0.143\">either</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.34%); opacity: 0.80\" title=\"-0.024\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.19%); opacity: 0.81\" title=\"-0.145\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 96.27%); opacity: 0.81\" title=\"-0.077\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.34%); opacity: 0.80\" title=\"-0.024\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.74%); opacity: 0.81\" title=\"0.063\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.46%); opacity: 0.80\" title=\"-0.005\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.98%); opacity: 0.80\" title=\"0.012\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.04%); opacity: 0.81\" title=\"-0.084\">broken</span><span style=\"opacity: 0.80\"> up </span><span style=\"background-color: hsl(0, 100.00%, 98.58%); opacity: 0.80\" title=\"-0.019\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.90%); opacity: 0.81\" title=\"-0.088\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 96.27%); opacity: 0.81\" title=\"-0.077\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.34%); opacity: 0.80\" title=\"-0.024\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.74%); opacity: 0.81\" title=\"0.063\">have</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 99.46%); opacity: 0.80\" title=\"-0.005\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.33%); opacity: 0.81\" title=\"0.106\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.77%); opacity: 0.81\" title=\"0.160\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.54%); opacity: 0.81\" title=\"-0.099\">surgically</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 96.87%); opacity: 0.81\" title=\"-0.060\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.90%); opacity: 0.81\" title=\"0.155\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.53%); opacity: 0.82\" title=\"0.248\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.64%); opacity: 0.80\" title=\"-0.018\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 96.85%); opacity: 0.81\" title=\"-0.060\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.37%); opacity: 0.80\" title=\"0.047\">x</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 73.18%); opacity: 0.91\" title=\"1.286\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.25%); opacity: 0.81\" title=\"0.108\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.38%); opacity: 0.82\" title=\"-0.213\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.60%); opacity: 0.81\" title=\"0.067\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.61%); opacity: 0.81\" title=\"-0.097\">mention</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.39%); opacity: 0.80\" title=\"-0.023\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.45%); opacity: 0.80\" title=\"-0.005\">she</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(120, 100.00%, 92.88%); opacity: 0.82\" title=\"0.193\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.97%); opacity: 0.81\" title=\"0.086\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 77.73%); opacity: 0.89\" title=\"-0.986\">kidney</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 79.82%); opacity: 0.88\" title=\"-0.857\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.51%); opacity: 0.81\" title=\"-0.100\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.48%); opacity: 0.85\" title=\"-0.589\">children</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 95.51%); opacity: 0.81\" title=\"-0.100\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.61%); opacity: 0.81\" title=\"-0.097\">the</span><span style=\"opacity: 0.80\"> childbirth </span><span style=\"background-color: hsl(0, 100.00%, 87.04%); opacity: 0.84\" title=\"-0.455\">hurt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.23%); opacity: 0.80\" title=\"-0.050\">less</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=sci.med\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.995</b>, score <b>6.780</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.861\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.082\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 98.12%); opacity: 0.80\" title=\"-0.029\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.12%); opacity: 0.80\" title=\"-0.029\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.69%); opacity: 0.85\" title=\"0.525\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.36%); opacity: 0.81\" title=\"0.105\">from</span><span style=\"opacity: 0.80\"> my </span><span style=\"background-color: hsl(0, 100.00%, 91.63%); opacity: 0.82\" title=\"-0.244\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.92%); opacity: 0.81\" title=\"-0.119\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.03%); opacity: 0.89\" title=\"1.031\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.45%); opacity: 0.87\" title=\"0.819\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.74%); opacity: 0.80\" title=\"-0.038\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.94%); opacity: 0.81\" title=\"-0.119\">isn</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(0, 100.00%, 97.67%); opacity: 0.80\" title=\"-0.039\">t</span><span style=\"opacity: 0.80\"> any\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 79.36%); opacity: 0.88\" title=\"0.885\">medication</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(0, 100.00%, 98.31%); opacity: 0.80\" title=\"-0.025\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.23%); opacity: 0.81\" title=\"-0.109\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.02%); opacity: 0.81\" title=\"-0.084\">anything</span><span style=\"opacity: 0.80\"> about them except </span><span style=\"background-color: hsl(120, 100.00%, 95.14%); opacity: 0.81\" title=\"0.112\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.71%); opacity: 0.82\" title=\"0.200\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.277\">pain</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 97.11%); opacity: 0.80\" title=\"0.053\">either</span><span style=\"opacity: 0.80\"> they pass, </span><span style=\"background-color: hsl(120, 100.00%, 97.76%); opacity: 0.80\" title=\"0.037\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.03%); opacity: 0.80\" title=\"-0.031\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.77%); opacity: 0.80\" title=\"-0.037\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.43%); opacity: 0.80\" title=\"-0.005\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.40%); opacity: 0.81\" title=\"-0.073\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.23%); opacity: 0.81\" title=\"-0.109\">broken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.02%); opacity: 0.80\" title=\"0.056\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.00%); opacity: 0.80\" title=\"0.031\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.34%); opacity: 0.80\" title=\"0.024\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 97.76%); opacity: 0.80\" title=\"0.037\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.03%); opacity: 0.80\" title=\"-0.031\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.77%); opacity: 0.80\" title=\"-0.037\">have</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 99.43%); opacity: 0.80\" title=\"-0.005\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.40%); opacity: 0.81\" title=\"-0.073\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.35%); opacity: 0.82\" title=\"-0.176\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.66%); opacity: 0.81\" title=\"0.095\">surgically</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "when i was in, the x-</span><span style=\"background-color: hsl(0, 100.00%, 85.53%); opacity: 0.85\" title=\"-0.533\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.95%); opacity: 0.82\" title=\"0.191\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.43%); opacity: 0.82\" title=\"-0.172\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.27%); opacity: 0.82\" title=\"-0.218\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.70%); opacity: 0.81\" title=\"-0.162\">mention</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.71%); opacity: 0.80\" title=\"-0.038\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.00%); opacity: 0.81\" title=\"-0.085\">she</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(0, 100.00%, 95.17%); opacity: 0.81\" title=\"-0.111\">d</span><span style=\"opacity: 0.80\"> had </span><span style=\"background-color: hsl(120, 100.00%, 77.03%); opacity: 0.89\" title=\"1.031\">kidney</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 79.83%); opacity: 0.88\" title=\"0.856\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.03%); opacity: 0.81\" title=\"0.116\">and</span><span style=\"opacity: 0.80\"> children, </span><span style=\"background-color: hsl(120, 100.00%, 95.03%); opacity: 0.81\" title=\"0.116\">and</span><span style=\"opacity: 0.80\"> the childbirth </span><span style=\"background-color: hsl(120, 100.00%, 91.16%); opacity: 0.82\" title=\"0.263\">hurt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.24%); opacity: 0.81\" title=\"-0.078\">less</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=soc.religion.christian\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.005</b>, score <b>-5.232</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.38%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.276\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.81%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.956\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 93.22%); opacity: 0.82\" title=\"0.180\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.03%); opacity: 0.81\" title=\"0.084\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.45%); opacity: 0.83\" title=\"-0.339\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.23%); opacity: 0.80\" title=\"-0.050\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.108\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.43%); opacity: 0.82\" title=\"0.211\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.05%); opacity: 0.81\" title=\"0.150\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.12%); opacity: 0.86\" title=\"-0.721\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.29%); opacity: 0.85\" title=\"-0.546\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.53%); opacity: 0.81\" title=\"0.069\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.46%); opacity: 0.82\" title=\"0.210\">isn</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(120, 100.00%, 96.34%); opacity: 0.81\" title=\"0.075\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.73%); opacity: 0.80\" title=\"-0.038\">any</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 86.68%); opacity: 0.84\" title=\"-0.473\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.82\" title=\"0.171\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.40%); opacity: 0.81\" title=\"0.073\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.86%); opacity: 0.81\" title=\"0.157\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.26%); opacity: 0.81\" title=\"0.077\">anything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.27%); opacity: 0.81\" title=\"0.108\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.34%); opacity: 0.81\" title=\"0.106\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.80%); opacity: 0.80\" title=\"0.036\">except</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.64%); opacity: 0.80\" title=\"-0.040\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.48%); opacity: 0.81\" title=\"-0.135\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.86%); opacity: 0.96\" title=\"-1.816\">pain</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 91.86%); opacity: 0.82\" title=\"-0.234\">either</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.57%); opacity: 0.80\" title=\"-0.042\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.06%); opacity: 0.80\" title=\"0.030\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.41%); opacity: 0.80\" title=\"-0.046\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.76%); opacity: 0.81\" title=\"0.092\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.95%); opacity: 0.81\" title=\"0.086\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.49%); opacity: 0.81\" title=\"0.071\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.98%); opacity: 0.81\" title=\"0.117\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.75%); opacity: 0.83\" title=\"0.325\">broken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.69%); opacity: 0.80\" title=\"0.017\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.76%); opacity: 0.81\" title=\"0.063\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.96%); opacity: 0.81\" title=\"0.153\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.64%); opacity: 0.80\" title=\"0.018\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.76%); opacity: 0.81\" title=\"0.092\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.95%); opacity: 0.81\" title=\"0.086\">have</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 96.49%); opacity: 0.81\" title=\"0.071\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.69%); opacity: 0.81\" title=\"0.065\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.64%); opacity: 0.82\" title=\"0.203\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.96%); opacity: 0.81\" title=\"-0.118\">surgically</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 95.76%); opacity: 0.81\" title=\"-0.092\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.63%); opacity: 0.81\" title=\"-0.096\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.55%); opacity: 0.81\" title=\"-0.132\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.11%); opacity: 0.80\" title=\"-0.053\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.40%); opacity: 0.80\" title=\"-0.046\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.51%); opacity: 0.81\" title=\"0.070\">x</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 94.16%); opacity: 0.81\" title=\"0.146\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.02%); opacity: 0.81\" title=\"-0.116\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.98%); opacity: 0.83\" title=\"0.361\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.18%); opacity: 0.83\" title=\"0.306\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.43%); opacity: 0.83\" title=\"0.387\">mention</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.79%); opacity: 0.81\" title=\"0.091\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.48%); opacity: 0.80\" title=\"0.021\">she</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(120, 100.00%, 97.93%); opacity: 0.80\" title=\"0.033\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.56%); opacity: 0.81\" title=\"-0.068\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.12%); opacity: 0.86\" title=\"-0.721\">kidney</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 83.62%); opacity: 0.86\" title=\"-0.636\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.46%); opacity: 0.80\" title=\"-0.044\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.38%); opacity: 0.84\" title=\"0.489\">children</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 95.71%); opacity: 0.81\" title=\"0.094\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.27%); opacity: 0.81\" title=\"0.108\">the</span><span style=\"opacity: 0.80\"> childbirth </span><span style=\"background-color: hsl(0, 100.00%, 95.94%); opacity: 0.81\" title=\"-0.087\">hurt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.25%); opacity: 0.81\" title=\"0.143\">less</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eli5.lime import TextExplainer\n",
    "\n",
    "te = TextExplainer()\n",
    "te.fit(doc, pipe.predict_proba)\n",
    "te.show_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it work\n",
    "\n",
    "Explanation makes sense, but how did we get it, and how can we be sure this is how the pipeline works? A simple sanity check is to remove or change the highlighted words, to confirm that they change the outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.065 alt.atheism\n",
      "0.151 comp.graphics\n",
      "0.352 sci.med\n",
      "0.432 soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "doc2 = re.sub(r'(recall|kidney|stones|medication|pain|tech)', '', doc)\n",
    "print_prediction(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted probabilities changed a lot indeed. \n",
    "\n",
    "And in fact, TextExplainer did something similar to get the explanation. TextExplainer generated a lot of texts similar to the document (by removing some of the words or chars), and then trained a white-box classifier which predicts the output of the black-box classifier (not the true labels!). The explanation we saw is for this white-box classifier.\n",
    "\n",
    "This approach follows the LIME algorithm; for text data the algorithm is actually pretty straightforward:\n",
    "\n",
    "1. generate distorted versions of the text;\n",
    "2. predict probabilities for these distorted texts \n",
    "   using the black-box classifier;\n",
    "3. train another classifier (one of those eli5 supports) which \n",
    "   tries to predict output of a black-box classifier on these texts.\n",
    "\n",
    "The algorithm works because even though it could be hard or impossible to approximate a black-box classifier globally (for every possible text), approximating it in a small neighbourhood near a given text often works well, even with simple white-box classifiers.\n",
    "\n",
    "Generated samples (distorted texts) are available in `samples_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   from my bout  kidney , there isn't \n",
      "medication   do    except  the .\n",
      "\n",
      "Either  pass,         ,   \n",
      "   .\n",
      "\n",
      "   , the -  happened  mention  she'd  kidney\n",
      "stones and children,  the childbirth  .\n"
     ]
    }
   ],
   "source": [
    "print(te.samples_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default TextExplainer generated 5000 distorted texts (use `n_samples` argument to change the amount):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(te.samples_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained white-box classifier and vectorizer are available as `vec_` and `clf_` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w+\\\\b', tokenizer=None,\n",
       "         vocabulary=None),\n",
       " SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='elasticnet', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x112c056c0>,\n",
       "        shuffle=True, verbose=0, warm_start=False))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.vec_, te.clf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Should we trust the explanation?\n",
    "\n",
    "Ok, this sounds fine, but how can we be sure that this simple text classification pipeline approximated the black-box classifier well?\n",
    "\n",
    "One way to do that is to check the quality on a held-out dataset (which is also generated). TextExplainer does that by default and stores metrics in `metrics_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_KL_divergence': 0.02246869327029901, 'score': 0.98189887288325461}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'score' is an accuracy score weighted by cosine distance between generated sample and the original document (i.e. texts which are closer to the example are more important). Accuracy shows how good are 'top 1' predictions. \n",
    "* 'mean_KL_divergence' is a mean [KullbackLeibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) for all target classes; it is also weighted by distance. KL divergence shows how well are probabilities approximated; 0.0 means a perfect match.\n",
    "\n",
    "In this example both accuracy and KL divergence are very good; it means our white-box classifier usually assigns the same labels as the black-box classifier on the dataset we generated, and its predicted probabilities are close to those predicted by our LSA+SVM pipeline. So it is likely (though not guaranteed, we'll discuss it later) that the explanation is correct and can be trusted.\n",
    "\n",
    "When working with LIME (e.g. via TextExplainer) it is always a good idea to check these scores. If they are not good then you can tell that something is not right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make it fail\n",
    "\n",
    "By default TextExplainer uses a very basic text processing pipeline: Logistic Regression trained on bag-of-words and bag-of-bigrams features (see `te.clf_` and `te.vec_` attributes). It limits a set of black-box classifiers it can explain: because the text is seen as \"bag of words/ngrams\", the default white-box pipeline can't distinguish e.g. between the same word in the beginning of the document and in the end of the document. Bigrams help to alleviate the problem in practice, but not completely. \n",
    "\n",
    "Black-box classifiers which use features like \"text length\" (not directly related to tokens) can be also hard to approximate using the default bag-of-words/ngrams model. \n",
    "\n",
    "This kind of failure is usually detectable though - scores (accuracy and KL divergence) will be low. Let's check it on a completely synthetic example - a black-box classifier which assigns a class based on oddity of document length and on a presence of 'medication' word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=sci.med\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.998</b>, score <b>6.245</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.256\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 98.33%); opacity: 0.80\" title=\"0.062\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.33%); opacity: 0.80\" title=\"0.062\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.37%); opacity: 0.81\" title=\"0.266\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.64%); opacity: 0.80\" title=\"0.046\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.38%); opacity: 0.80\" title=\"0.118\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.34%); opacity: 0.81\" title=\"0.268\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.61%); opacity: 0.80\" title=\"0.048\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.33%); opacity: 0.80\" title=\"0.121\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.31%); opacity: 0.80\" title=\"-0.063\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.95%); opacity: 0.81\" title=\"0.390\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.88%); opacity: 0.81\" title=\"0.396\">isn</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(0, 100.00%, 95.55%); opacity: 0.81\" title=\"-0.251\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.71%); opacity: 0.83\" title=\"0.950\">any</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"5.791\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.03%); opacity: 0.84\" title=\"1.158\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.85%); opacity: 0.81\" title=\"0.153\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.28%); opacity: 0.81\" title=\"0.273\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.41%); opacity: 0.80\" title=\"-0.058\">anything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.98%); opacity: 0.81\" title=\"0.218\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.85%); opacity: 0.80\" title=\"0.089\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.78%); opacity: 0.81\" title=\"0.233\">except</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.24%); opacity: 0.81\" title=\"-0.198\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.77%); opacity: 0.81\" title=\"-0.234\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.00%); opacity: 0.82\" title=\"-0.480\">pain</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 95.64%); opacity: 0.81\" title=\"-0.244\">either</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.88%); opacity: 0.80\" title=\"0.001\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.36%); opacity: 0.80\" title=\"-0.119\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.35%); opacity: 0.80\" title=\"0.061\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.15%); opacity: 0.80\" title=\"0.072\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.35%); opacity: 0.80\" title=\"-0.120\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.32%); opacity: 0.80\" title=\"0.017\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.70%); opacity: 0.80\" title=\"0.098\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.99%); opacity: 0.80\" title=\"0.144\">broken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.88%); opacity: 0.81\" title=\"-0.307\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.71%); opacity: 0.81\" title=\"-0.163\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.49%); opacity: 0.81\" title=\"0.256\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 94.91%); opacity: 0.81\" title=\"0.305\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.15%); opacity: 0.80\" title=\"0.072\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.35%); opacity: 0.80\" title=\"-0.120\">have</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 99.32%); opacity: 0.80\" title=\"0.017\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.53%); opacity: 0.80\" title=\"0.052\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.88%); opacity: 0.80\" title=\"0.001\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.80%); opacity: 0.81\" title=\"0.157\">surgically</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 97.12%); opacity: 0.80\" title=\"0.135\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.40%); opacity: 0.81\" title=\"0.186\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.41%); opacity: 0.81\" title=\"-0.185\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.13%); opacity: 0.80\" title=\"0.024\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 94.23%); opacity: 0.81\" title=\"0.365\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.26%); opacity: 0.80\" title=\"0.126\">x</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 95.34%); opacity: 0.81\" title=\"0.268\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.58%); opacity: 0.80\" title=\"0.049\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.11%); opacity: 0.81\" title=\"0.207\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.47%); opacity: 0.80\" title=\"-0.055\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.81%); opacity: 0.81\" title=\"-0.157\">mention</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.36%); opacity: 0.82\" title=\"-0.445\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.36%); opacity: 0.82\" title=\"-0.445\">she</span><span style=\"opacity: 0.80\">'</span><span style=\"background-color: hsl(120, 100.00%, 99.10%); opacity: 0.80\" title=\"0.026\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.42%); opacity: 0.81\" title=\"-0.347\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.93%); opacity: 0.80\" title=\"-0.033\">kidney</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 99.81%); opacity: 0.80\" title=\"-0.003\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.55%); opacity: 0.81\" title=\"-0.427\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.34%); opacity: 0.80\" title=\"-0.121\">children</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.06%); opacity: 0.80\" title=\"0.027\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.93%); opacity: 0.81\" title=\"-0.303\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.46%); opacity: 0.80\" title=\"0.055\">childbirth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.23%); opacity: 0.81\" title=\"0.199\">hurt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.87%); opacity: 0.81\" title=\"0.226\">less</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_proba_len(docs):\n",
    "    # nasty predict_proba - the result is based on document length,\n",
    "    # and also on a presence of \"medication\"\n",
    "    proba = [\n",
    "        [0, 0, 1.0, 0] if len(doc) % 2 or 'medication' in doc else [1.0, 0, 0, 0] \n",
    "        for doc in docs\n",
    "    ]\n",
    "    return np.array(proba)    \n",
    "\n",
    "te3 = TextExplainer().fit(doc, predict_proba_len)\n",
    "te3.show_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextExplainer correctly figured out that 'medication' is important, but failed to account for \"len(doc) % 2\" condition, so the explanation is incomplete. We can detect this failure by looking at metrics - they are low:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_KL_divergence': 0.30581890571484338, 'score': 0.79670704047322449}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te3.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If (a big if...) we suspect that the fact document length is even or odd is important, it is possible to customize TextExplainer to check this hypothesis. \n",
    "\n",
    "To do that, we need to create a vectorizer which returns both \"is odd\" feature and bag-of-words features, and pass this vectorizer to TextExplainer. This vectorizer should follow scikit-learn API. The easiest way is to use FeatureUnion - just make sure all transformers joined by FeatureUnion have get_feature_names() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 1.0, 'mean_KL_divergence': 0.024643780992576535}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=sci.med\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.996</b>, score <b>5.494</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.684\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        countvectorizer: Highlighted in text (sum)\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.36%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.064\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.127\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        doclength__is_even\n",
       "    </td>\n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <b>countvectorizer:</b> <span style=\"opacity: 0.80\">as i </span><span style=\"background-color: hsl(120, 100.00%, 99.45%); opacity: 0.80\" title=\"0.017\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.35%); opacity: 0.80\" title=\"0.022\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.33%); opacity: 0.80\" title=\"0.023\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.06%); opacity: 0.80\" title=\"0.037\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.89%); opacity: 0.80\" title=\"0.047\">with</span><span style=\"opacity: 0.80\"> kidney </span><span style=\"background-color: hsl(120, 100.00%, 99.09%); opacity: 0.80\" title=\"0.036\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.09%); opacity: 0.80\" title=\"0.036\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.67%); opacity: 0.80\" title=\"0.008\">isn</span><span style=\"opacity: 0.80\">'t </span><span style=\"background-color: hsl(120, 100.00%, 89.77%); opacity: 0.83\" title=\"1.125\">any</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"7.891\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.71%); opacity: 0.83\" title=\"1.295\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.30%); opacity: 0.80\" title=\"0.087\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.53%); opacity: 0.80\" title=\"0.014\">do</span><span style=\"opacity: 0.80\"> anything </span><span style=\"background-color: hsl(120, 100.00%, 98.12%); opacity: 0.80\" title=\"0.100\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.00%); opacity: 0.80\" title=\"0.040\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.34%); opacity: 0.80\" title=\"0.022\">except</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.53%); opacity: 0.80\" title=\"0.014\">relieve</span><span style=\"opacity: 0.80\"> the pain.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 99.25%); opacity: 0.80\" title=\"0.027\">either</span><span style=\"opacity: 0.80\"> they </span><span style=\"background-color: hsl(120, 100.00%, 99.10%); opacity: 0.80\" title=\"0.035\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.14%); opacity: 0.80\" title=\"0.033\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.47%); opacity: 0.80\" title=\"0.016\">they</span><span style=\"opacity: 0.80\"> have </span><span style=\"background-color: hsl(120, 100.00%, 98.95%); opacity: 0.80\" title=\"0.043\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.01%); opacity: 0.80\" title=\"0.040\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.09%); opacity: 0.80\" title=\"0.035\">broken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.56%); opacity: 0.80\" title=\"0.013\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.89%); opacity: 0.80\" title=\"0.047\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.01%); opacity: 0.80\" title=\"0.040\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.14%); opacity: 0.80\" title=\"0.033\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.47%); opacity: 0.80\" title=\"0.016\">they</span><span style=\"opacity: 0.80\"> have\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 98.95%); opacity: 0.80\" title=\"0.043\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.79%); opacity: 0.80\" title=\"0.004\">be</span><span style=\"opacity: 0.80\"> extracted surgically.\n",
       "\n",
       "when i </span><span style=\"background-color: hsl(120, 100.00%, 98.52%); opacity: 0.80\" title=\"0.071\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.99%); opacity: 0.80\" title=\"0.196\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.16%); opacity: 0.80\" title=\"0.097\">the</span><span style=\"opacity: 0.80\"> x-ray </span><span style=\"background-color: hsl(120, 100.00%, 98.24%); opacity: 0.80\" title=\"0.091\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.07%); opacity: 0.80\" title=\"0.037\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.10%); opacity: 0.80\" title=\"0.035\">to</span><span style=\"opacity: 0.80\"> mention </span><span style=\"background-color: hsl(0, 100.00%, 97.99%); opacity: 0.80\" title=\"-0.110\">that</span><span style=\"opacity: 0.80\"> she'd had kidney\n",
       "stones </span><span style=\"background-color: hsl(120, 100.00%, 99.07%); opacity: 0.80\" title=\"0.037\">and</span><span style=\"opacity: 0.80\"> children, </span><span style=\"background-color: hsl(120, 100.00%, 99.07%); opacity: 0.80\" title=\"0.037\">and</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 98.19%); opacity: 0.80\" title=\"0.095\">childbirth</span><span style=\"opacity: 0.80\"> hurt less</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\\n       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\\n       penalty='elasticnet', power_t=0.5,\\n       random_state=<mtrand.RandomState object at 0x111d838b8>,\\n       shuffle=True, verbose=0, warm_start=False)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='sci.med', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='countvectorizer__medication', weight=5.0349213820344323, std=None), FeatureWeight(feature='countvectorizer__any medication', weight=1.4501502609848895, std=None), FeatureWeight(feature='countvectorizer__medication that', weight=1.4056072317702553, std=None), FeatureWeight(feature='countvectorizer__to', weight=0.10467500948160485, std=None), FeatureWeight(feature='countvectorizer__in the', weight=0.096819324451507455, std=None), FeatureWeight(feature='countvectorizer__childbirth', weight=0.094611917495694878, std=None), FeatureWeight(feature='countvectorizer__with', weight=0.094170447379665498, std=None), FeatureWeight(feature='countvectorizer__tech', weight=0.09109512971120165, std=None), FeatureWeight(feature='countvectorizer__can', weight=0.086659725422937553, std=None), FeatureWeight(feature='countvectorizer__and', weight=0.07373310545683108, std=None), FeatureWeight(feature='countvectorizer__was in', weight=0.071057318877381676, std=None), FeatureWeight(feature='countvectorizer__about', weight=0.068936672866279761, std=None), FeatureWeight(feature='countvectorizer__isn', weight=0.067192364365446414, std=None), FeatureWeight(feature='countvectorizer__or they', weight=0.065173489509814095, std=None), FeatureWeight(feature='countvectorizer__sound', weight=0.040041942182065603, std=None), FeatureWeight(feature='countvectorizer__happened', weight=0.036830007068615229, std=None), FeatureWeight(feature='countvectorizer__stones there', weight=0.035612860976353709, std=None), FeatureWeight(feature='countvectorizer__be broken', weight=0.035456884509219286, std=None), FeatureWeight(feature='countvectorizer__pass', weight=0.035089057842312393, std=None), FeatureWeight(feature='countvectorizer__about them', weight=0.031351888460587334, std=None), FeatureWeight(feature='countvectorizer__in', weight=0.027809418108587978, std=None), FeatureWeight(feature='countvectorizer__either', weight=0.026972567886821314, std=None), FeatureWeight(feature='countvectorizer__my bout', weight=0.022676794569767924, std=None), FeatureWeight(feature='countvectorizer__from', weight=0.021886504643786046, std=None), FeatureWeight(feature='countvectorizer__recall', weight=0.017352906844229646, std=None), FeatureWeight(feature='countvectorizer__to be', weight=0.017146130310244177, std=None), FeatureWeight(feature='countvectorizer__bout', weight=0.014541463161556205, std=None), FeatureWeight(feature='countvectorizer__do', weight=0.013906831413458075, std=None), FeatureWeight(feature='countvectorizer__relieve', weight=0.013830413835389526, std=None), FeatureWeight(feature='countvectorizer__except', weight=0.013291633830163912, std=None), FeatureWeight(feature='countvectorizer__up', weight=0.012671238630139789, std=None), FeatureWeight(feature='countvectorizer__them except', weight=0.0090010068443696131, std=None)], neg=[FeatureWeight(feature='doclength__is_even', weight=-3.1269029841048517, std=None), FeatureWeight(feature='countvectorizer__any', weight=-0.2663240385703679, std=None), FeatureWeight(feature='countvectorizer__that', weight=-0.22067525850937947, std=None), FeatureWeight(feature='<BIAS>', weight=-0.063545213236340922, std=None), FeatureWeight(feature='countvectorizer__isn any', weight=-0.05894290065964148, std=None)], pos_remaining=0, neg_remaining=0), proba=0.99590498932171212, score=5.4938825358450289, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"as i recall from my bout with kidney stones, there isn't any\\nmedication that can do anything about them except relieve the pain.\\n\\neither they pass, or they have to be broken up with sound, or they have\\nto be extracted surgically.\\n\\nwhen i was in, the x-ray tech happened to mention that she'd had kidney\\nstones and children, and the childbirth hurt less\", spans=[('recall', [(5, 11)], 0.017352906844229646), ('from', [(12, 16)], 0.021886504643786046), ('bout', [(20, 24)], 0.014541463161556205), ('with', [(25, 29)], 0.094170447379665498), ('isn', [(51, 54)], 0.067192364365446414), ('any', [(57, 60)], -0.2663240385703679), ('medication', [(61, 71)], 5.0349213820344323), ('that', [(72, 76)], -0.22067525850937947), ('can', [(77, 80)], 0.086659725422937553), ('do', [(81, 83)], 0.013906831413458075), ('about', [(93, 98)], 0.068936672866279761), ('except', [(104, 110)], 0.013291633830163912), ('relieve', [(111, 118)], 0.013830413835389526), ('either', [(130, 136)], 0.026972567886821314), ('pass', [(142, 146)], 0.035089057842312393), ('to', [(161, 163)], 0.10467500948160485), ('up', [(174, 176)], 0.012671238630139789), ('with', [(177, 181)], 0.094170447379665498), ('sound', [(182, 187)], 0.040041942182065603), ('to', [(202, 204)], 0.10467500948160485), ('in', [(242, 244)], 0.027809418108587978), ('tech', [(256, 260)], 0.09109512971120165), ('happened', [(261, 269)], 0.036830007068615229), ('to', [(270, 272)], 0.10467500948160485), ('that', [(281, 285)], -0.22067525850937947), ('and', [(310, 313)], 0.07373310545683108), ('and', [(324, 327)], 0.07373310545683108), ('childbirth', [(332, 342)], 0.094611917495694878), ('my bout', [(17, 19), (20, 24)], 0.022676794569767924), ('stones there', [(37, 43), (45, 50)], 0.035612860976353709), ('isn any', [(51, 54), (57, 60)], -0.05894290065964148), ('any medication', [(57, 60), (61, 71)], 1.4501502609848895), ('medication that', [(61, 71), (72, 76)], 1.4056072317702553), ('about them', [(93, 98), (99, 103)], 0.031351888460587334), ('them except', [(99, 103), (104, 110)], 0.0090010068443696131), ('or they', [(148, 150), (151, 155)], 0.065173489509814095), ('to be', [(161, 163), (164, 166)], 0.017146130310244177), ('be broken', [(164, 166), (167, 173)], 0.035456884509219286), ('or they', [(189, 191), (192, 196)], 0.065173489509814095), ('to be', [(202, 204), (205, 207)], 0.017146130310244177), ('was in', [(238, 241), (242, 244)], 0.071057318877381676), ('in the', [(242, 244), (246, 249)], 0.096819324451507455)], preserve_density=False, vec_name='countvectorizer')], other=FeatureWeights(pos=[FeatureWeight(feature=<FormattedFeatureName 'countvectorizer: Highlighted in text (sum)'>, weight=8.6843307331862256, std=None)], neg=[FeatureWeight(feature='doclength__is_even', weight=-3.1269029841048517, std=None), FeatureWeight(feature='<BIAS>', weight=-0.063545213236340922, std=None)], pos_remaining=0, neg_remaining=0)))], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_union\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DocLength(TransformerMixin):\n",
    "    def fit(self, X, y=None):  # some boilerplate\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            # note that we needed both positive and negative \n",
    "            # feature - otherwise for linear model there won't \n",
    "            # be a feature to show in 50% cases\n",
    "            [len(doc) % 2, not len(doc) % 2] \n",
    "            for doc in X\n",
    "        ]\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return ['is_odd', 'is_even']\n",
    "\n",
    "vec = make_union(DocLength(), CountVectorizer(ngram_range=(1,2)))\n",
    "te4 = TextExplainer(vec=vec).fit(doc[:-1], predict_proba_len)\n",
    "\n",
    "print(te4.metrics_)\n",
    "te4.explain_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! It was a toy example, but the idea stands - if you think something could be important, add it to the mix as a feature for TextExplainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make it fail, again\n",
    "\n",
    "Another possible issue is the dataset generation method. Not only feature extraction should be powerful enough, but auto-generated texts also should be diverse enough. \n",
    "\n",
    "TextExplainer removes random words by default, so by default it can't e.g. provide a good explanation for a black-box classifier which works on character level. To explain such black-box classifiers we need to change both dataset generation method (change/remove individual characters, not only words) and feature extraction method (e.g. use char ngrams instead of words and word ngrams). \n",
    "\n",
    "If this makes a more powerful explanation engine why not always use it? The problem is that it is much more resource intensive - you need a lot more samples to get non-noisy results. Generally speaking, to do an efficient explanation we should make some assumptions about black-box classifier, such as:\n",
    "\n",
    "1. it uses words as features and doesn't take word position in account;\n",
    "2. it uses words as features and takes word positions in account;\n",
    "3. it uses words ngrams as features (it is partially covered by (2));\n",
    "4. it uses char ngrams as features, positions don't matter (i.e. an ngram means the same everywhere);\n",
    "5. it uses arbitrary attention over the text characters, i.e. every part of text could be potentionally important for a classifier on its own;\n",
    "6. it is important to have a particular token at a particular position, e.g. \"third token is X\", and if we delete 2nd token then prediction changes not because 2nd token changed, but because 3rd token is shifted.\n",
    "\n",
    "Depending on assumptions we should choose both dataset generation method and a white-box classifier. There is a tradeoff between genereality and speed. Simple bag-of-words assumptions allow for fast sample generation, and just a few hundreds of samples could be required to get an OK quality if the assumption is correct. But such generation methods / models will fail to explain a more complex classifier properly. On the other hand, allowing for each character to be important is a more powerful method, but it can require a lot of samples (maybe hundreds thousands) and a lot of CPU time to get non-noisy results.\n",
    "\n",
    "What's bad about this kind of failure (wrong assumption about the black-box pipeline) is that it could be impossible to detect the failure by looking at the scores. Scores could be high because generated dataset is not diverse enough, not because our approximation is good.\n",
    "\n",
    "It means that it is important to understand the \"lenses\" you're looking through when using LIME to explain a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
