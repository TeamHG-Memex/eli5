{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocablen = 10000\n",
    "maxlen = 128 # for batched input\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# vectorized data\n",
    "# https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=vocablen, \n",
    "                                    seed=113,\n",
    "                                    start_char=1,\n",
    "                                    oov_char=2,\n",
    "                                    index_from=3,\n",
    "                                    )\n",
    "\n",
    "np.load = np_load_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] 1\n",
      "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717] 0\n",
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0], y_train[0])\n",
    "print(x_test[0], y_test[0])\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# index to decode vectors into tokens and vice versa\n",
    "# 0 is reserved\n",
    "# word -> num\n",
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "the and a\n"
     ]
    }
   ],
   "source": [
    "print(word_index['the'])\n",
    "reversed_word_index = {v:k for k, v in word_index.items()}\n",
    "print(reversed_word_index[1], reversed_word_index[2], reversed_word_index[3],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve special characters\n",
    "word_index = {k:v+2 for k, v in word_index.items()}\n",
    "word_index['<PAD>'] = 0\n",
    "word_index['<START>'] = 1\n",
    "word_index['<OOV>'] = 2\n",
    "\n",
    "# limit number of words\n",
    "word_index = {k:v for k, v in word_index.items() if v < vocablen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 10000\n"
     ]
    }
   ],
   "source": [
    "print(word_index['<OOV>'], word_index['the'], len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num -> word\n",
    "reversed_word_index = {v:k for k, v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <START> <OOV> the\n"
     ]
    }
   ],
   "source": [
    "print(reversed_word_index[0], reversed_word_index[1], reversed_word_index[2], reversed_word_index[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad samples\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, \n",
    "                            maxlen=maxlen,\n",
    "                            padding='post',\n",
    "                            truncating='post',\n",
    "                            value=word_index['<PAD>']\n",
    "                            )\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, \n",
    "                            maxlen=maxlen,\n",
    "                            padding='post',\n",
    "                            truncating='post',\n",
    "                            value=word_index['<PAD>']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(X):\n",
    "    if not isinstance(X[0], list):\n",
    "        # add batch dim\n",
    "        X = [X]\n",
    "    tokens = []\n",
    "    for x in X:\n",
    "        tokenized = [reversed_word_index.get(num-1, '<OOV>') for num in x]\n",
    "        tokens.append(tokenized)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <START> is an amazing actor and now the same being director <START> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <START> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and\n"
     ]
    }
   ],
   "source": [
    "s = ' '.join(decode(x_train[0])[0])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 8)           80000     \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "masking_3 (Masking)          (None, None, 8)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         37376     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 64)          41216     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 32)                10368     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 169,233\n",
      "Trainable params: 169,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Embedding,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LSTM,\n",
    "    Masking,\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "    # mask before embedding\n",
    "    Embedding(vocablen, 8),\n",
    "    Masking(mask_value=word_index['<PAD>']),\n",
    "    Masking(mask_value=word_index['<START>']),    \n",
    "    Masking(mask_value=word_index['<OOV>']),\n",
    "    Bidirectional(LSTM(64,\n",
    "                return_sequences=True,\n",
    "                )),\n",
    "    Bidirectional(LSTM(32, \n",
    "                return_sequences=True,\n",
    "                )),\n",
    "    Bidirectional(LSTM(16)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12500 samples, validate on 12500 samples\n",
      "Epoch 1/5\n",
      " - 64s - loss: 0.6932 - acc: 0.5007 - val_loss: 0.6930 - val_acc: 0.5150\n",
      "Epoch 2/5\n",
      " - 57s - loss: 0.6902 - acc: 0.5065 - val_loss: 0.6681 - val_acc: 0.5187\n",
      "Epoch 3/5\n",
      " - 56s - loss: 0.5734 - acc: 0.6984 - val_loss: 0.4894 - val_acc: 0.7822\n",
      "Epoch 4/5\n",
      " - 56s - loss: 0.4018 - acc: 0.8336 - val_loss: 0.4248 - val_acc: 0.8111\n",
      "Epoch 5/5\n",
      " - 57s - loss: 0.2908 - acc: 0.8918 - val_loss: 0.4047 - val_acc: 0.8327\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "history = model.fit(x_train, y_train, \n",
    "      epochs=epochs, batch_size=batch_size, verbose=2,\n",
    "      validation_split=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 332s 13ms/step\n",
      "[0.43191788868904113, 0.81504]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-sentiment-classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
