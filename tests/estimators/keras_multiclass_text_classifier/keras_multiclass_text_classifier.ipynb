{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['database.sqlite', 'consumer_complaints.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# keras model\n",
    "# for text classification, with multiple classes (multi-class)\n",
    "# but single label\n",
    "# character-level tokenization\n",
    "# with fixed length input\n",
    "# based on convolutional layers\n",
    "\n",
    "# using customer complaints dataset\n",
    "# we classify a narrative text about an issue into a product category\n",
    "# https://www.kaggle.com/cfpb/us-consumer-finance-complaints\n",
    "\n",
    "# See also\n",
    "# https://www.kaggle.com/kadhambari/multi-class-text-classification\n",
    "# https://www.kaggle.com/anucool007/multi-class-text-classification-bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions for later\n",
    "\n",
    "def dict_to_csv(d, path):\n",
    "    df = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('../input/consumer_complaints.csv', usecols=('product', 'consumer_complaint_narrative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            product consumer_complaint_narrative\n",
       "0          Mortgage                          NaN\n",
       "1          Mortgage                          NaN\n",
       "2  Credit reporting                          NaN\n",
       "3      Student loan                          NaN\n",
       "4   Debt collection                          NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190126</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>XXXX has claimed I owe them {$27.00} for XXXX ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190135</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Due to inconsistencies in the amount owed that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190155</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190207</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>I have an open and current mortgage with Chase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190208</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                product                       consumer_complaint_narrative\n",
       "190126  Debt collection  XXXX has claimed I owe them {$27.00} for XXXX ...\n",
       "190135    Consumer Loan  Due to inconsistencies in the amount owed that...\n",
       "190155         Mortgage  In XX/XX/XXXX my wages that I earned at my job...\n",
       "190207         Mortgage  I have an open and current mortgage with Chase...\n",
       "190208         Mortgage  XXXX was submitted XX/XX/XXXX. At the time I s..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove nan's\n",
    "df = df.dropna() # drop row if have nan in any column\n",
    "print(len(df))\n",
    "df.head()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, ..., 7, 2, 2]), Index(['Debt collection', 'Consumer Loan', 'Mortgage', 'Credit card',\n",
      "       'Credit reporting', 'Student loan', 'Bank account or service',\n",
      "       'Payday loan', 'Money transfers', 'Other financial service',\n",
      "       'Prepaid card'],\n",
      "      dtype='object'))\n"
     ]
    }
   ],
   "source": [
    "# this turns each string into a number (most popular are lowest)\n",
    "product_encoding = pd.factorize(df['product'])\n",
    "print(product_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 7 2 2]\n",
      "Index(['Debt collection', 'Consumer Loan', 'Mortgage', 'Credit card',\n",
      "       'Credit reporting', 'Student loan', 'Bank account or service',\n",
      "       'Payday loan', 'Money transfers', 'Other financial service',\n",
      "       'Prepaid card'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "labels, index = product_encoding\n",
    "print(labels) # encoding for each product in the dataset\n",
    "print(index) # index -> string map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Debt collection': 0, 'Consumer Loan': 1, 'Mortgage': 2, 'Credit card': 3, 'Credit reporting': 4, 'Student loan': 5, 'Bank account or service': 6, 'Payday loan': 7, 'Money transfers': 8, 'Other financial service': 9, 'Prepaid card': 10}\n",
      "{0: 'Debt collection', 1: 'Consumer Loan', 2: 'Mortgage', 3: 'Credit card', 4: 'Credit reporting', 5: 'Student loan', 6: 'Bank account or service', 7: 'Payday loan', 8: 'Money transfers', 9: 'Other financial service', 10: 'Prepaid card'}\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# build label <-> index maps to use later\n",
    "product_to_id = {name: i for i, name in enumerate(index)}\n",
    "id_to_product = {i: name for i, name in enumerate(index)}\n",
    "print(product_to_id)\n",
    "print(id_to_product)\n",
    "print(len(index)) # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_csv(product_to_id, 'labels_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debt collection 17552\n",
      "Consumer Loan 3678\n",
      "Mortgage 14919\n",
      "Credit card 7929\n",
      "Credit reporting 12526\n",
      "Student loan 2128\n",
      "Bank account or service 5711\n",
      "Payday loan 726\n",
      "Money transfers 666\n",
      "Other financial service 110\n",
      "Prepaid card 861\n"
     ]
    }
   ],
   "source": [
    "# note that the classes are imbalanced\n",
    "for product in index:\n",
    "    print(product, len(df.loc[df['product'] == product]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66806\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] 0\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode\n",
    "y = keras.utils.to_categorical(labels)\n",
    "print(len(y))\n",
    "print(y[0], labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input with character level tokenization and embeddings\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tok = Tokenizer(num_words=None, # don't limit number of characters\n",
    "                lower=False, # don't lower\n",
    "                char_level=True, # character-level tokenization\n",
    "                oov_token='<OOV>', # token for unknown characters\n",
    "                                   # FIXME: multi-character token but should be single char?\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XXXX has claimed I owe them {$27.00} for XXXX years despite the PROOF of PAYMENT I sent them : canceled check and their ownPAID INVOICE for {$27.00}! \\nThey continue to insist I owe them and collection agencies are after me. \\nHow can I stop this harassment for a bill I already paid four years ago? \\n'\n",
      " 'Due to inconsistencies in the amount owed that I was told by M & T Bank and the amount that was reported to the credit reporting agencies, I was advised to write a good will letter in order to address the issue and request the negative entry be removed from my credit report all together. I had a vehicle that was stolen and it was declared a total loss by insurance company. The insurance company and the GAP insurancw companypaid the outstanding balance of the loan, but I was told by M & T Bank that there was still a balance due on the loan. In good faith, without having received any proof as to why there was still a balance, I made a partial payment towards the remaining debt. I then sent the goodwill letter still offering to pay the remainder of the debt, but in exchange for the removal of the negative entry on my credit report. At one point, in XXXX 2015, per my credit monitoring agency, it showed a delinquent balance of {$0.00}, but when I checked my credit report again on XXXX XXXX 2015, there was a delinquent balance of {$1400.00}. The monies from the GAP insurance and my insurance company has been paid, M & T Bank says that I still owe {$620.00}, of which {$210.00} has already been paid. I contacted M & T Bank via return receipt mail, but I have not been given the courtesy of a response yet. \\n']\n"
     ]
    }
   ],
   "source": [
    "texts = df['consumer_complaint_narrative'].values\n",
    "print(texts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 10, 10, 10, 2, 12, 5, 11, 2, 15, 14, 5, 8, 16, 3, 13, 2, 26, 2, 6, 21, 3, 2, 4, 12, 3, 16, 2, 54, 51, 53, 74, 23, 29, 29, 55, 2, 20, 6, 9, 2, 10, 10, 10, 10, 2, 18, 3, 5, 9, 11, 2, 13, 3, 11, 19, 8, 4, 3, 2, 4, 12, 3, 2, 46, 40, 38, 38, 44, 2, 6, 20, 2, 46, 31, 64, 42, 33, 39, 30, 2, 26, 2, 11, 3, 7, 4, 2, 4, 12, 3, 16, 2, 71, 2, 15, 5, 7, 15, 3, 14, 3, 13, 2, 15, 12, 3, 15, 28, 2, 5, 7, 13, 2, 4, 12, 3, 8, 9, 2, 6, 21, 7, 46, 31, 26, 45, 2, 26, 39, 69, 38, 26, 35, 33, 2, 20, 6, 9, 2, 54, 51, 53, 74, 23, 29, 29, 55, 66, 2, 32, 30, 12, 3, 18, 2, 15, 6, 7, 4, 8, 7, 17, 3, 2, 4, 6, 2, 8, 7, 11, 8, 11, 4, 2, 26, 2, 6, 21, 3, 2, 4, 12, 3, 16, 2, 5, 7, 13, 2, 15, 6, 14, 14, 3, 15, 4, 8, 6, 7, 2, 5, 22, 3, 7, 15, 8, 3, 11, 2, 5, 9, 3, 2, 5, 20, 4, 3, 9, 2, 16, 3, 23, 2, 32, 48, 6, 21, 2, 15, 5, 7, 2, 26, 2, 11, 4, 6, 19, 2, 4, 12, 8, 11, 2, 12, 5, 9, 5, 11, 11, 16, 3, 7, 4, 2, 20, 6, 9, 2, 5, 2, 24, 8, 14, 14, 2, 26, 2, 5, 14, 9, 3, 5, 13, 18, 2, 19, 5, 8, 13, 2, 20, 6, 17, 9, 2, 18, 3, 5, 9, 11, 2, 5, 22, 6, 72, 2, 32], [45, 17, 3, 2, 4, 6, 2, 8, 7, 15, 6, 7, 11, 8, 11, 4, 3, 7, 15, 8, 3, 11, 2, 8, 7, 2, 4, 12, 3, 2, 5, 16, 6, 17, 7, 4, 2, 6, 21, 3, 13, 2, 4, 12, 5, 4, 2, 26, 2, 21, 5, 11, 2, 4, 6, 14, 13, 2, 24, 18, 2, 42, 2, 79, 2, 30, 2, 50, 5, 7, 28, 2, 5, 7, 13, 2, 4, 12, 3, 2, 5, 16, 6, 17, 7, 4, 2, 4, 12, 5, 4, 2, 21, 5, 11, 2, 9, 3, 19, 6, 9, 4, 3, 13, 2, 4, 6, 2, 4, 12, 3, 2, 15, 9, 3, 13, 8, 4, 2, 9, 3, 19, 6, 9, 4, 8, 7, 22, 2, 5, 22, 3, 7, 15, 8, 3, 11, 27, 2, 26, 2, 21, 5, 11, 2, 5, 13, 25, 8, 11, 3, 13, 2, 4, 6, 2, 21, 9, 8, 4, 3, 2, 5, 2, 22, 6, 6, 13, 2, 21, 8, 14, 14, 2, 14, 3, 4, 4, 3, 9, 2, 8, 7, 2, 6, 9, 13, 3, 9, 2, 4, 6, 2, 5, 13, 13, 9, 3, 11, 11, 2, 4, 12, 3, 2, 8, 11, 11, 17, 3, 2, 5, 7, 13, 2, 9, 3, 47, 17, 3, 11, 4, 2, 4, 12, 3, 2, 7, 3, 22, 5, 4, 8, 25, 3, 2, 3, 7, 4, 9, 18, 2, 24, 3, 2, 9, 3, 16, 6, 25, 3, 13, 2, 20, 9, 6, 16, 2, 16, 18, 2, 15, 9, 3, 13, 8, 4, 2, 9, 3, 19, 6, 9, 4, 2, 5, 14, 14, 2, 4, 6, 22, 3, 4, 12, 3, 9, 23, 2, 26, 2, 12, 5, 13, 2, 5, 2, 25, 3, 12, 8, 15, 14, 3, 2, 4, 12, 5, 4, 2, 21, 5, 11, 2, 11, 4, 6, 14, 3, 7, 2, 5, 7, 13, 2, 8, 4, 2, 21, 5, 11, 2, 13, 3, 15, 14, 5, 9, 3, 13, 2, 5, 2, 4, 6, 4, 5, 14, 2, 14, 6, 11, 11, 2, 24, 18, 2, 8, 7, 11, 17, 9, 5, 7, 15, 3, 2, 15, 6, 16, 19, 5, 7, 18, 23, 2, 30, 12, 3, 2, 8, 7, 11, 17, 9, 5, 7, 15, 3, 2, 15, 6, 16, 19, 5, 7, 18, 2, 5, 7, 13, 2, 4, 12, 3, 2, 65, 31, 46, 2, 8, 7, 11, 17, 9, 5, 7, 15, 21, 2, 15, 6, 16, 19, 5, 7, 18, 19, 5, 8, 13, 2, 4, 12, 3, 2, 6, 17, 4, 11, 4, 5, 7, 13, 8, 7, 22, 2, 24, 5, 14, 5, 7, 15, 3, 2, 6, 20, 2, 4, 12, 3, 2, 14, 6, 5, 7, 27, 2, 24, 17, 4, 2, 26, 2, 21, 5, 11, 2, 4, 6, 14, 13, 2, 24, 18, 2, 42, 2, 79, 2, 30, 2, 50, 5, 7, 28, 2, 4, 12, 5, 4, 2, 4, 12, 3, 9, 3, 2, 21, 5, 11, 2, 11, 4, 8, 14, 14, 2, 5, 2, 24, 5, 14, 5, 7, 15, 3, 2, 13, 17, 3, 2, 6, 7, 2, 4, 12, 3, 2, 14, 6, 5, 7, 23, 2, 26, 7, 2, 22, 6, 6, 13, 2, 20, 5, 8, 4, 12, 27, 2, 21, 8, 4, 12, 6, 17, 4, 2, 12, 5, 25, 8, 7, 22, 2, 9, 3, 15, 3, 8, 25, 3, 13, 2, 5, 7, 18, 2, 19, 9, 6, 6, 20, 2, 5, 11, 2, 4, 6, 2, 21, 12, 18, 2, 4, 12, 3, 9, 3, 2, 21, 5, 11, 2, 11, 4, 8, 14, 14, 2, 5, 2, 24, 5, 14, 5, 7, 15, 3, 27, 2, 26, 2, 16, 5, 13, 3, 2, 5, 2, 19, 5, 9, 4, 8, 5, 14, 2, 19, 5, 18, 16, 3, 7, 4, 2, 4, 6, 21, 5, 9, 13, 11, 2, 4, 12, 3, 2, 9, 3, 16, 5, 8, 7, 8, 7, 22, 2, 13, 3, 24, 4, 23, 2, 26, 2, 4, 12, 3, 7, 2, 11, 3, 7, 4, 2, 4, 12, 3, 2, 22, 6, 6, 13, 21, 8, 14, 14, 2, 14, 3, 4, 4, 3, 9, 2, 11, 4, 8, 14, 14, 2, 6, 20, 20, 3, 9, 8, 7, 22, 2, 4, 6, 2, 19, 5, 18, 2, 4, 12, 3, 2, 9, 3, 16, 5, 8, 7, 13, 3, 9, 2, 6, 20, 2, 4, 12, 3, 2, 13, 3, 24, 4, 27, 2, 24, 17, 4, 2, 8, 7, 2, 3, 41, 15, 12, 5, 7, 22, 3, 2, 20, 6, 9, 2, 4, 12, 3, 2, 9, 3, 16, 6, 25, 5, 14, 2, 6, 20, 2, 4, 12, 3, 2, 7, 3, 22, 5, 4, 8, 25, 3, 2, 3, 7, 4, 9, 18, 2, 6, 7, 2, 16, 18, 2, 15, 9, 3, 13, 8, 4, 2, 9, 3, 19, 6, 9, 4, 23, 2, 31, 4, 2, 6, 7, 3, 2, 19, 6, 8, 7, 4, 27, 2, 8, 7, 2, 10, 10, 10, 10, 2, 53, 29, 43, 56, 27, 2, 19, 3, 9, 2, 16, 18, 2, 15, 9, 3, 13, 8, 4, 2, 16, 6, 7, 8, 4, 6, 9, 8, 7, 22, 2, 5, 22, 3, 7, 15, 18, 27, 2, 8, 4, 2, 11, 12, 6, 21, 3, 13, 2, 5, 2, 13, 3, 14, 8, 7, 47, 17, 3, 7, 4, 2, 24, 5, 14, 5, 7, 15, 3, 2, 6, 20, 2, 54, 51, 29, 23, 29, 29, 55, 27, 2, 24, 17, 4, 2, 21, 12, 3, 7, 2, 26, 2, 15, 12, 3, 15, 28, 3, 13, 2, 16, 18, 2, 15, 9, 3, 13, 8, 4, 2, 9, 3, 19, 6, 9, 4, 2, 5, 22, 5, 8, 7, 2, 6, 7, 2, 10, 10, 10, 10, 2, 10, 10, 10, 10, 2, 53, 29, 43, 56, 27, 2, 4, 12, 3, 9, 3, 2, 21, 5, 11, 2, 5, 2, 13, 3, 14, 8, 7, 47, 17, 3, 7, 4, 2, 24, 5, 14, 5, 7, 15, 3, 2, 6, 20, 2, 54, 51, 43, 68, 29, 29, 23, 29, 29, 55, 23, 2, 30, 12, 3, 2, 16, 6, 7, 8, 3, 11, 2, 20, 9, 6, 16, 2, 4, 12, 3, 2, 65, 31, 46, 2, 8, 7, 11, 17, 9, 5, 7, 15, 3, 2, 5, 7, 13, 2, 16, 18, 2, 8, 7, 11, 17, 9, 5, 7, 15, 3, 2, 15, 6, 16, 19, 5, 7, 18, 2, 12, 5, 11, 2, 24, 3, 3, 7, 2, 19, 5, 8, 13, 27, 2, 42, 2, 79, 2, 30, 2, 50, 5, 7, 28, 2, 11, 5, 18, 11, 2, 4, 12, 5, 4, 2, 26, 2, 11, 4, 8, 14, 14, 2, 6, 21, 3, 2, 54, 51, 70, 53, 29, 23, 29, 29, 55, 27, 2, 6, 20, 2, 21, 12, 8, 15, 12, 2, 54, 51, 53, 43, 29, 23, 29, 29, 55, 2, 12, 5, 11, 2, 5, 14, 9, 3, 5, 13, 18, 2, 24, 3, 3, 7, 2, 19, 5, 8, 13, 23, 2, 26, 2, 15, 6, 7, 4, 5, 15, 4, 3, 13, 2, 42, 2, 79, 2, 30, 2, 50, 5, 7, 28, 2, 25, 8, 5, 2, 9, 3, 4, 17, 9, 7, 2, 9, 3, 15, 3, 8, 19, 4, 2, 16, 5, 8, 14, 27, 2, 24, 17, 4, 2, 26, 2, 12, 5, 25, 3, 2, 7, 6, 4, 2, 24, 3, 3, 7, 2, 22, 8, 25, 3, 7, 2, 4, 12, 3, 2, 15, 6, 17, 9, 4, 3, 11, 18, 2, 6, 20, 2, 5, 2, 9, 3, 11, 19, 6, 7, 11, 3, 2, 18, 3, 4, 23, 2, 32]]\n"
     ]
    }
   ],
   "source": [
    "x = tok.texts_to_sequences(texts)\n",
    "print(x[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(x)\n",
    "df.to_csv('x_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "np.savetxt('y_data.csv', y, fmt=\"%d\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2\n",
      "<PAD> <OOV>  \n"
     ]
    }
   ],
   "source": [
    "# create word index to use later\n",
    "\n",
    "# word -> index map\n",
    "word_index = tok.word_index\n",
    "word_index['<PAD>'] = 0 # set unused index to padding token\n",
    "print(word_index['<PAD>'], word_index['<OOV>'], word_index[' '])\n",
    "\n",
    "# index -> word map\n",
    "reversed_word_index = {v:k for k, v in word_index.items()}\n",
    "print(reversed_word_index[0], reversed_word_index[1], reversed_word_index[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_csv(word_index, 'word_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_to_tokens(sample):\n",
    "    return [reversed_word_index.get(num, '<OOV>') for num in sample]\n",
    "    \n",
    "def tokens_to_string(tokens):\n",
    "    return ''.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66806 66806\n"
     ]
    }
   ],
   "source": [
    "print(len(x), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad to fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66806\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# find a good length to pad to\n",
    "lengths = [len(sample) for sample in x]\n",
    "print(len(lengths))\n",
    "print(lengths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193.0\n"
     ]
    }
   ],
   "source": [
    "p = np.percentile(lengths, 95)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "maxlen = int(p)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66806\n",
      "3193\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x = pad_sequences(x,\n",
    "                  padding='post',\n",
    "                  truncating='post',\n",
    "                  value=word_index['<PAD>'],\n",
    "                  maxlen=maxlen,\n",
    "                )\n",
    "print(len(x))\n",
    "print(len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33403 33403\n",
      "33403 33403\n"
     ]
    }
   ],
   "source": [
    "# split train and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.5, random_state=42)\n",
    "\n",
    "print(len(x_train), len(x_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have been battling with portfolio recovery and Foster, Garbus & Garbus for over a year regarding a debt that is not mine. I continue receiving letters from Foster, Garbus XXXX Garbus regarding same debt although I 've submitted documents to Foster, Garbus & Garbus proving that I DO NOT OWE said debt. These guys went as far as having my XXXX XXXX account frozen last year and I thought the issue was resolved once I submitted my documents. \n",
      "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "Debt collection\n"
     ]
    }
   ],
   "source": [
    "print(tokens_to_string(vectorized_to_tokens(x_test[0])))\n",
    "print(id_to_product[np.argmax(y_test[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3193, 8)           816       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 3179, 128)         15488     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3179, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1589, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1580, 128)         163968    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1580, 128)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 790, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 786, 128)          82048     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 786, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 393, 128)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                363       \n",
      "=================================================================\n",
      "Total params: 266,811\n",
      "Trainable params: 266,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Embedding,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    MaxPooling1D,\n",
    "    AveragePooling1D,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling1D,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(len(word_index), 8, input_length=maxlen),\n",
    "    Conv1D(128, 15, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(128, 10, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    AveragePooling1D(2),\n",
    "    Conv1D(128, 5, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling1D(2),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(11, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46764 samples, validate on 20042 samples\n",
      "Epoch 1/47\n",
      " - 32s - loss: 1.8898 - acc: 0.3192 - val_loss: 1.8835 - val_acc: 0.3178\n",
      "Epoch 2/47\n",
      " - 28s - loss: 1.7228 - acc: 0.3783 - val_loss: 1.7772 - val_acc: 0.3734\n",
      "Epoch 3/47\n",
      " - 28s - loss: 1.6462 - acc: 0.4060 - val_loss: 1.7345 - val_acc: 0.3787\n",
      "Epoch 4/47\n",
      " - 28s - loss: 1.6082 - acc: 0.4186 - val_loss: 1.7285 - val_acc: 0.3829\n",
      "Epoch 5/47\n",
      " - 28s - loss: 1.5499 - acc: 0.4397 - val_loss: 1.6215 - val_acc: 0.4213\n",
      "Epoch 6/47\n",
      " - 28s - loss: 1.4896 - acc: 0.4604 - val_loss: 1.5544 - val_acc: 0.4566\n",
      "Epoch 7/47\n",
      " - 28s - loss: 1.4121 - acc: 0.4882 - val_loss: 1.5276 - val_acc: 0.4759\n",
      "Epoch 8/47\n",
      " - 28s - loss: 1.3569 - acc: 0.5093 - val_loss: 1.4624 - val_acc: 0.5010\n",
      "Epoch 9/47\n",
      " - 28s - loss: 1.3058 - acc: 0.5326 - val_loss: 1.4180 - val_acc: 0.5188\n",
      "Epoch 10/47\n",
      " - 28s - loss: 1.2667 - acc: 0.5527 - val_loss: 1.3598 - val_acc: 0.5362\n",
      "Epoch 11/47\n",
      " - 28s - loss: 1.2349 - acc: 0.5682 - val_loss: 1.3686 - val_acc: 0.5476\n",
      "Epoch 12/47\n",
      " - 28s - loss: 1.2074 - acc: 0.5821 - val_loss: 1.3619 - val_acc: 0.5433\n",
      "Epoch 13/47\n",
      " - 28s - loss: 1.1687 - acc: 0.5996 - val_loss: 1.2960 - val_acc: 0.5869\n",
      "Epoch 14/47\n",
      " - 28s - loss: 1.1356 - acc: 0.6123 - val_loss: 1.2463 - val_acc: 0.5984\n",
      "Epoch 15/47\n",
      " - 28s - loss: 1.1057 - acc: 0.6251 - val_loss: 1.2514 - val_acc: 0.6018\n",
      "Epoch 16/47\n",
      " - 28s - loss: 1.0802 - acc: 0.6388 - val_loss: 1.2198 - val_acc: 0.6168\n",
      "Epoch 17/47\n",
      " - 28s - loss: 1.0537 - acc: 0.6486 - val_loss: 1.1703 - val_acc: 0.6327\n",
      "Epoch 18/47\n",
      " - 28s - loss: 1.0335 - acc: 0.6577 - val_loss: 1.1498 - val_acc: 0.6364\n",
      "Epoch 19/47\n",
      " - 28s - loss: 1.0010 - acc: 0.6696 - val_loss: 1.1048 - val_acc: 0.6528\n",
      "Epoch 20/47\n",
      " - 28s - loss: 0.9718 - acc: 0.6804 - val_loss: 1.0803 - val_acc: 0.6623\n",
      "Epoch 21/47\n",
      " - 28s - loss: 0.9455 - acc: 0.6912 - val_loss: 1.0939 - val_acc: 0.6609\n",
      "Epoch 22/47\n",
      " - 28s - loss: 0.9188 - acc: 0.7003 - val_loss: 1.0534 - val_acc: 0.6664\n",
      "Epoch 23/47\n",
      " - 28s - loss: 0.8983 - acc: 0.7096 - val_loss: 1.0189 - val_acc: 0.6865\n",
      "Epoch 24/47\n",
      " - 28s - loss: 0.8703 - acc: 0.7193 - val_loss: 0.9962 - val_acc: 0.6921\n",
      "Epoch 25/47\n",
      " - 28s - loss: 0.8511 - acc: 0.7285 - val_loss: 0.9665 - val_acc: 0.7048\n",
      "Epoch 26/47\n",
      " - 28s - loss: 0.8270 - acc: 0.7358 - val_loss: 0.9591 - val_acc: 0.7048\n",
      "Epoch 27/47\n",
      " - 28s - loss: 0.8202 - acc: 0.7408 - val_loss: 0.9489 - val_acc: 0.7125\n",
      "Epoch 28/47\n",
      " - 28s - loss: 0.8049 - acc: 0.7463 - val_loss: 0.9246 - val_acc: 0.7205\n",
      "Epoch 29/47\n",
      " - 28s - loss: 0.7933 - acc: 0.7494 - val_loss: 0.9296 - val_acc: 0.7193\n",
      "Epoch 30/47\n",
      " - 28s - loss: 0.7700 - acc: 0.7591 - val_loss: 0.8918 - val_acc: 0.7329\n",
      "Epoch 31/47\n",
      " - 28s - loss: 0.7602 - acc: 0.7607 - val_loss: 0.9116 - val_acc: 0.7222\n",
      "Epoch 32/47\n",
      " - 28s - loss: 0.7515 - acc: 0.7641 - val_loss: 0.8774 - val_acc: 0.7372\n",
      "Epoch 33/47\n",
      " - 28s - loss: 0.7403 - acc: 0.7694 - val_loss: 0.8670 - val_acc: 0.7380\n",
      "Epoch 34/47\n",
      " - 28s - loss: 0.7337 - acc: 0.7703 - val_loss: 0.9209 - val_acc: 0.7174\n",
      "Epoch 35/47\n",
      " - 28s - loss: 0.7283 - acc: 0.7724 - val_loss: 0.8586 - val_acc: 0.7379\n",
      "Epoch 36/47\n",
      " - 28s - loss: 0.7170 - acc: 0.7750 - val_loss: 0.8514 - val_acc: 0.7404\n",
      "Epoch 37/47\n",
      " - 28s - loss: 0.7039 - acc: 0.7809 - val_loss: 0.8811 - val_acc: 0.7306\n",
      "Epoch 38/47\n",
      " - 28s - loss: 0.7070 - acc: 0.7799 - val_loss: 0.8296 - val_acc: 0.7463\n",
      "Epoch 39/47\n",
      " - 28s - loss: 0.6903 - acc: 0.7843 - val_loss: 0.8283 - val_acc: 0.7499\n",
      "Epoch 40/47\n",
      " - 28s - loss: 0.6796 - acc: 0.7877 - val_loss: 0.8457 - val_acc: 0.7434\n",
      "Epoch 41/47\n",
      " - 28s - loss: 0.6754 - acc: 0.7896 - val_loss: 0.8836 - val_acc: 0.7309\n",
      "Epoch 42/47\n",
      " - 28s - loss: 0.6725 - acc: 0.7897 - val_loss: 0.8091 - val_acc: 0.7544\n",
      "Epoch 43/47\n",
      " - 28s - loss: 0.6591 - acc: 0.7933 - val_loss: 0.8102 - val_acc: 0.7522\n",
      "Epoch 44/47\n",
      " - 28s - loss: 0.6521 - acc: 0.7964 - val_loss: 0.8092 - val_acc: 0.7541\n",
      "Epoch 45/47\n",
      " - 28s - loss: 0.6464 - acc: 0.7980 - val_loss: 0.8127 - val_acc: 0.7533\n",
      "Epoch 46/47\n",
      " - 28s - loss: 0.6414 - acc: 0.7970 - val_loss: 0.7861 - val_acc: 0.7592\n",
      "Epoch 47/47\n",
      " - 28s - loss: 0.6323 - acc: 0.8023 - val_loss: 0.7738 - val_acc: 0.7649\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "epochs = 47\n",
    "batch_size = 512\n",
    "\n",
    "history = model.fit(x, \n",
    "                    y, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size,\n",
    "                    verbose=2, \n",
    "                    validation_split=0.3,\n",
    "                   )\n",
    "\n",
    "# baseline: 1/11 ~= 0.1 accuracy with random guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33403/33403 [==============================] - 6s 194us/step\n",
      "[0.6686020720609237, 0.7996886507253484]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_text_model_multiclass.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
